use std::{
    collections::{hash_map::Entry, HashMap, HashSet},
    env, fs,
    ops::Deref,
    path::{Path, PathBuf},
    sync::Arc,
    time::{Duration, Instant},
};

use notify::DebouncedEvent;

use common::{
    eyre::{bail, Result},
    indexmap::IndexMap,
    itertools::Itertools,
    maplit::hashset,
    serde::Serialize,
    serde_with::skip_serializing_none,
    strum::Display,
    tokio::{
        self,
        sync::{broadcast, mpsc, Mutex, RwLock},
        task::JoinHandle,
    },
    tracing,
};
use events::publish;
use formats::FormatSpec;
use graph::{Graph, PlanOptions, PlanOrdering, PlanScope};
use graph_triples::{resources, Relations, Resource, TagMap};
use kernels::{KernelInfos, KernelSpace, KernelSymbols};
use node_address::{Address, AddressMap};
use node_patch::{apply, diff, merge, Patch};
use node_pointer::{resolve, resolve_mut};
use node_reshape::reshape;
use node_validate::Validator;

use providers::DetectItem;
use stencila_schema::{Article, InlineContent, Node, Parameter};

use crate::{
    assemble::assemble,
    compile::compile,
    execute::execute,
    messages::{
        AssembleRequest, CancelRequest, CompileRequest, ExecuteRequest, PatchRequest, RequestId,
        Response, When, WriteRequest,
    },
};

#[derive(Debug, Serialize, Display)]
#[serde(rename_all = "lowercase", crate = "common::serde")]
#[strum(serialize_all = "lowercase")]
enum DocumentEventType {
    Deleted,
    Renamed,
    Modified,
    Patched,
    Encoded,
}

#[skip_serializing_none]
#[derive(Debug, Serialize)]
#[serde(crate = "common::serde")]
struct DocumentEvent {
    /// The type of event
    #[serde(rename = "type")]
    type_: DocumentEventType,

    /// The `Patch` associated with a `Patched` event
    patch: Option<Patch>,
}

/// The status of a document with respect to on-disk synchronization
#[derive(Debug, Clone, Serialize, Display)]
#[serde(rename_all = "lowercase", crate = "common::serde")]
#[strum(serialize_all = "lowercase")]
enum DocumentStatus {
    /// The document `content` is the same as on disk at its `path`.
    Synced,
    /// The document `content` has modifications that have not yet
    /// been written to its `path`.
    Unwritten,
    /// The document `path` has modifications that have not yet
    /// been read into its `content`.
    Unread,
    /// The document `path` no longer exists and is now set to `None`.
    /// The user will need to choose a new path for the document if they
    /// want to save it.
    Deleted,
}

pub type CallDocuments = HashMap<String, Mutex<Document>>;

/// An in-memory representation of a document
#[derive(Debug, Serialize)]
#[serde(crate = "common::serde")]
pub struct Document {
    /// The document identifier
    pub id: String,

    /// The absolute path of the document's file.
    pub path: PathBuf,

    /// The project directory for this document.
    ///
    /// Used to restrict file links (e.g. image paths) to within
    /// the project for both security and reproducibility reasons.
    /// For documents opened from within a project, this will be project directory.
    /// For "orphan" documents (opened by themselves) this will be the
    /// parent directory of the document. When the document is compiled,
    /// an error will be returned if a file link is outside of the root.
    project: PathBuf,

    /// Whether or not the document's file is in the temporary
    /// directory.
    temporary: bool,

    /// The synchronization status of the document.
    /// This is orthogonal to `temporary` because a document's
    /// `content` can be synced or un-synced with the file system
    /// regardless of whether or not its `path` is temporary..
    status: DocumentStatus,

    /// The last time that the document was written to disk.
    ///
    /// Used to ignore file modification notification events generated by
    /// this application itself.
    #[serde(skip)]
    last_write: Arc<RwLock<Instant>>,

    /// The name of the document
    ///
    /// Usually the filename from the `path` but "Untitled"
    /// for temporary documents.
    name: String,

    /// The format of the document.
    ///
    /// On initialization, this is inferred, if possible, from the file name extension
    /// of the document's `path`. However, it may change whilst the document is
    /// open in memory (e.g. if the `load` function sets a different format).
    pub(crate) format: FormatSpec,

    /// Whether a HTML preview of the document is supported
    ///
    /// This is determined by the type of the `root` node of the document.
    /// Will be `true` if the `root` is a type for which HTML previews are
    /// implemented e.g. `Article`, `ImageObject` and `false` if the `root`
    /// is `None`, or of some other type e.g. `Entity`.
    ///
    /// This flag is intended for dynamically determining whether to open
    /// a preview panel for a document by default. Regardless of its value,
    /// a user should be able to open a preview panel, in HTML or some other
    /// format, for any document.
    previewable: bool,

    /// The current UTF8 string content of the document.
    ///
    /// When a document is `read()` from a file the `content` is the content
    /// of the file. The `content` may subsequently be changed using
    /// the `load()` function. A call to `write()` will write the content
    /// back to `path`.
    ///
    /// Skipped during serialization because will often be large.
    #[serde(skip)]
    pub(crate) content: String,

    /// The root Stencila Schema node of the document
    ///
    /// Can be any type of `Node` but defaults to an empty `Article`.
    ///
    /// A [`RwLock`] to enable separate, concurrent tasks to read (e.g. for dumping to some
    /// format) and write (e.g. to apply patches from clients) the node.
    ///
    /// Skipped during serialization because will often be large.
    #[serde(skip)]
    pub(crate) root: Arc<RwLock<Node>>,

    /// Addresses of nodes in `root` that have an `id`
    ///
    /// Used to fetch a particular node (and do something with it like `patch`
    /// or `execute` it) rather than walking the node tree looking for it.
    /// It is necessary to use [`Address`] here (rather than say raw pointers) because
    /// pointers or references will change as the document is patched.
    /// These addresses are shifted when the document is patched to account for this.
    #[serde(skip)]
    addresses: Arc<RwLock<AddressMap>>,

    /// Global tags defined in any of the document's code chunks
    #[allow(dead_code)]
    #[serde(skip)]
    tags: Arc<RwLock<TagMap>>,

    /// The kernel space for this document.
    ///
    /// This is where document variables are stored and executable nodes such as
    /// `CodeChunk`s and `Parameters`s are executed.
    #[serde(skip)]
    kernels: Arc<RwLock<KernelSpace>>,

    /// The set of dependency relations between this document, or nodes in this document,
    /// and other resources.
    ///
    /// Relations may be external (e.g. the document links to another `Resource::File`),
    /// or internal (e.g. the second code chunk uses a `Resource::Symbol` defined in the
    /// first code chunk).
    ///
    /// Stored for use in building the project's graph, but that may be removed
    /// in the future. Not serialized since this information is in `self.graph`.
    #[serde(skip)]
    pub relations: Relations,

    /// The document's dependency graph
    ///
    /// This is derived from `relations`.
    #[serde(skip)]
    pub graph: Arc<RwLock<Graph>>,

    /// The clients that are subscribed to each topic for this document
    ///
    /// Keeping track of client ids per topics allows for a some
    /// optimizations. For example, events will only be published on topics that have at least one
    /// subscriber.
    ///
    /// Valid subscription topics are the names of the `DocumentEvent` types:
    ///
    /// - `removed`: published when document file is deleted
    /// - `renamed`: published when document file is renamed
    /// - `modified`: published when document file is modified
    /// - `encoded:<format>` published when a document's content
    ///    is changed internally or externally and  conversions have been
    ///    completed e.g. `encoded:html`
    subscriptions: HashMap<String, HashSet<String>>,

    #[serde(skip)]
    patch_request_sender: mpsc::UnboundedSender<PatchRequest>,

    #[serde(skip)]
    assemble_request_sender: mpsc::Sender<AssembleRequest>,

    #[serde(skip)]
    compile_request_sender: mpsc::Sender<CompileRequest>,

    #[serde(skip)]
    execute_request_sender: mpsc::Sender<ExecuteRequest>,

    #[serde(skip)]
    cancel_request_sender: mpsc::Sender<CancelRequest>,

    #[serde(skip)]
    response_receiver: broadcast::Receiver<Response>,
}

#[allow(unused)]
impl Document {
    /// Milliseconds debounce delay for [`When::Soon`] assemble requests
    const ASSEMBLE_DEBOUNCE_MILLIS: u64 = 500;

    /// Milliseconds debounce delay for [`When::Soon`] compile requests
    const COMPILE_DEBOUNCE_MILLIS: u64 = 250;

    /// Milliseconds debounce delay for [`When::Soon`] execute requests
    const EXECUTE_DEBOUNCE_MILLIS: u64 = 750;

    /// Milliseconds debounce delay for [`When::Soon`] write requests
    const WRITE_DEBOUNCE_MILLIS: u64 = 1000;

    /// Milliseconds after writing document to ignore other events on its file
    const WRITE_MUTE_MILLIS: u64 = 500;

    /// Create a new empty document.
    ///
    /// # Arguments
    ///
    /// - `path`: The path of the document; defaults to a temporary path.
    /// - `format`: The format of the document; defaults to plain text.
    ///
    /// This function is intended to be used by editors when creating
    /// a new document. If the `path` is not specified, the created document
    /// will be `temporary: true` and have a temporary file path.
    #[tracing::instrument]
    fn new(path: Option<PathBuf>, format: Option<String>) -> Document {
        let id = uuids::generate("do").to_string();

        let format = if let Some(format) = format {
            formats::match_path(&format)
        } else if let Some(path) = path.as_ref() {
            formats::match_path(path)
        } else {
            formats::match_name("txt")
        }
        .spec();
        let previewable = format.preview;

        let (path, name, temporary) = match path {
            Some(path) => {
                let name = path
                    .file_name()
                    .map(|os_str| os_str.to_string_lossy())
                    .unwrap_or_else(|| "Untitled".into())
                    .into();

                (path, name, false)
            }
            None => {
                let path = env::temp_dir().join(
                    [
                        uuids::generate("fi").to_string(),
                        ".".to_string(),
                        format.extension.clone(),
                    ]
                    .concat(),
                );
                // Ensure that the file exists
                if !path.exists() {
                    fs::write(path.clone(), "").expect("Unable to write temporary file");
                }

                let name = "Untitled".into();

                (path, name, true)
            }
        };

        let project = path
            .parent()
            .expect("Unable to get path parent")
            .to_path_buf();

        let root = Arc::new(RwLock::new(Node::Article(Article::default())));
        let addresses = Arc::new(RwLock::new(AddressMap::default()));
        let call_docs = Arc::new(RwLock::new(CallDocuments::default()));
        let tags = Arc::new(RwLock::new(TagMap::default()));
        let graph = Arc::new(RwLock::new(Graph::default()));
        let kernels = Arc::new(RwLock::new(KernelSpace::new(Some(&project))));
        let last_write = Arc::new(RwLock::new(Instant::now()));

        let (patch_request_sender, mut patch_request_receiver) =
            mpsc::unbounded_channel::<PatchRequest>();

        let (assemble_request_sender, mut assemble_request_receiver) =
            mpsc::channel::<AssembleRequest>(100);

        let (compile_request_sender, mut compile_request_receiver) =
            mpsc::channel::<CompileRequest>(100);

        let (execute_request_sender, mut execute_request_receiver) =
            mpsc::channel::<ExecuteRequest>(100);

        let (cancel_request_sender, mut cancel_request_receiver) =
            mpsc::channel::<CancelRequest>(100);

        let (write_request_sender, mut write_request_receiver) =
            mpsc::unbounded_channel::<WriteRequest>();

        let (response_sender, mut response_receiver) = broadcast::channel::<Response>(1);

        let id_clone = id.clone();
        let root_clone = root.clone();
        let addresses_clone = addresses.clone();
        let compile_sender_clone = compile_request_sender.clone();
        let write_sender_clone = write_request_sender.clone();
        let response_sender_clone = response_sender.clone();
        tokio::spawn(async move {
            Self::patch_task(
                &id_clone,
                &root_clone,
                &addresses_clone,
                &compile_sender_clone,
                &write_sender_clone,
                &mut patch_request_receiver,
                &response_sender_clone,
            )
            .await
        });

        let id_clone = id.clone();
        let path_clone = path.clone();
        let project_clone = project.clone();
        let root_clone = root.clone();
        let addresses_clone = addresses.clone();
        let call_docs_clone = call_docs.clone();
        let patch_sender_clone = patch_request_sender.clone();
        let compile_sender_clone = compile_request_sender.clone();
        let execute_sender_clone = execute_request_sender.clone();
        let write_sender_clone = write_request_sender.clone();
        let response_sender_clone = response_sender.clone();
        tokio::spawn(async move {
            Self::assemble_task(
                &id_clone,
                &path_clone,
                &project_clone,
                &root_clone,
                &addresses_clone,
                &call_docs_clone,
                &patch_sender_clone,
                &compile_sender_clone,
                &execute_sender_clone,
                &write_sender_clone,
                &mut assemble_request_receiver,
                &response_sender_clone,
            )
            .await
        });

        let id_clone = id.clone();
        let path_clone = path.clone();
        let project_clone = project.clone();
        let root_clone = root.clone();
        let addresses_clone = addresses.clone();
        let tags_clone = tags.clone();
        let graph_clone = graph.clone();
        let patch_sender_clone = patch_request_sender.clone();
        let execute_sender_clone = execute_request_sender.clone();
        let write_sender_clone = write_request_sender.clone();
        let response_sender_clone = response_sender.clone();
        tokio::spawn(async move {
            Self::compile_task(
                &id_clone,
                &path_clone,
                &project_clone,
                &root_clone,
                &addresses_clone,
                &tags_clone,
                &graph_clone,
                &patch_sender_clone,
                &execute_sender_clone,
                &write_sender_clone,
                &mut compile_request_receiver,
                &response_sender_clone,
            )
            .await
        });

        let id_clone = id.clone();
        let path_clone = path.clone();
        let project_clone = project.clone();
        let root_clone = root.clone();
        let addresses_clone = addresses.clone();
        let tags_clone = tags.clone();
        let graph_clone = graph.clone();
        let kernels_clone = kernels.clone();
        let patch_sender_clone = patch_request_sender.clone();
        let response_sender_clone = response_sender.clone();
        tokio::spawn(async move {
            Self::execute_task(
                &id_clone,
                &path_clone,
                &project_clone,
                &root_clone,
                &addresses_clone,
                &tags_clone,
                &graph_clone,
                &kernels_clone,
                &call_docs,
                &patch_sender_clone,
                &write_request_sender,
                &mut cancel_request_receiver,
                &mut execute_request_receiver,
                &response_sender_clone,
            )
            .await
        });

        let root_clone = root.clone();
        let last_write_clone = last_write.clone();
        let path_clone = path.clone();
        let format_clone = Some(format.extension.clone());
        tokio::spawn(async move {
            Self::write_task(
                &root_clone,
                &last_write_clone,
                &path_clone,
                format_clone.as_deref(),
                &mut write_request_receiver,
                &response_sender,
            )
            .await
        });

        Document {
            id,
            path,
            project,
            temporary,
            name,
            format,
            previewable,

            status: DocumentStatus::Synced,
            last_write,
            content: Default::default(),

            root,
            addresses,
            tags,
            graph,
            kernels,

            relations: Default::default(),
            subscriptions: Default::default(),

            assemble_request_sender,
            patch_request_sender,
            compile_request_sender,
            execute_request_sender,
            cancel_request_sender,
            response_receiver,
        }
    }

    /// Create a new document, optionally with content.
    pub async fn create<P: AsRef<Path>>(
        path: Option<P>,
        content: Option<String>,
        format: Option<String>,
    ) -> Result<Document> {
        let path = path.map(|path| PathBuf::from(path.as_ref()));

        let mut document = Document::new(path, format);
        if let Some(content) = content {
            document.load(content, None).await?;
        }

        Ok(document)
    }

    /// Open a document from an existing file.
    ///
    /// # Arguments
    ///
    /// - `path`: The path of the file to create the document from
    ///
    /// - `format`: The format of the document. If `None` will be inferred from
    ///             the path's file extension.
    /// TODO: add project: Option<PathBuf> so that project can be explictly set
    #[tracing::instrument(skip(path))]
    pub async fn open<P: AsRef<Path>>(path: P, format: Option<String>) -> Result<Document> {
        let path = PathBuf::from(path.as_ref());

        let mut document = Document::new(Some(path.clone()), format);
        if let Err(error) = document.read(true).await {
            tracing::warn!("While reading document `{}`: {}", path.display(), error)
        };

        Ok(document)
    }

    /// Alter properties of the document
    ///
    /// # Arguments
    ///
    /// - `path`: The path of document's file
    ///
    /// - `format`: The format of the document. If `None` will be inferred from
    ///             the path's file extension.
    #[tracing::instrument(skip(self, path))]
    pub async fn alter<P: AsRef<Path>>(
        &mut self,
        path: Option<P>,
        format: Option<String>,
    ) -> Result<()> {
        if let Some(path) = &path {
            let path = path.as_ref().canonicalize()?;

            if path.is_dir() {
                bail!("Can not open a folder as a document; maybe try opening it as a project instead.")
            }

            self.project = path
                .parent()
                .expect("Unable to get path parent")
                .to_path_buf();

            self.name = path
                .file_name()
                .map(|os_str| os_str.to_string_lossy())
                .unwrap_or_else(|| "Untitled".into())
                .into();

            self.path = path;
            self.temporary = false;
            self.status = DocumentStatus::Unwritten;
        }

        if let Some(format) = format {
            self.format = formats::match_path(&format).spec();
        } else if let Some(path) = path {
            self.format = formats::match_path(&path).spec();
        };

        self.previewable = self.format.preview;

        // Given that the `format` may have changed, it is necessary
        // to update the `root` of the document
        self.update(true).await?;

        Ok(())
    }

    /// Read the document from the file system, update it and return its content.
    ///
    /// # Arguments
    ///
    /// - `force_load`: if `false` then if the file is empty, or is the same as the existing
    ///                 content then do not load the content into the document
    ///
    /// Using `force_load: false` is recommended when calling this function in response to
    /// file modification events as writes in quick succession can cause the file to be momentarily
    /// empty when read.
    ///
    /// Sets `status` to `Synced`. For binary files, does not actually read the content
    /// but will update the document nonetheless (possibly delegating the actual read
    /// to a binary or plugin)
    #[tracing::instrument(skip(self))]
    pub async fn read(&mut self, force_load: bool) -> Result<String> {
        let content = if !self.format.binary {
            let content = fs::read_to_string(&self.path)?;
            if force_load || (!content.is_empty() && content != self.content) {
                self.load(content.clone(), None).await?;
            }
            content
        } else {
            self.update(true).await?;
            "".to_string()
        };
        self.status = DocumentStatus::Synced;
        Ok(content)
    }

    /// Write the document to the file system, optionally load new `content`
    /// and set `format` before doing so.
    ///
    /// # Arguments
    ///
    /// - `content`: the content to load into the document
    /// - `format`: the format of the content; if not supplied assumed to be
    ///    the document's existing format.
    ///
    /// Sets `status` to `Synced`.
    #[tracing::instrument(skip(self, content))]
    pub async fn write(&mut self, content: Option<String>, format: Option<String>) -> Result<()> {
        if let Some(content) = content {
            self.load(content, format.clone()).await?;
        }

        let content_to_write = if let Some(input_format) = format.as_ref() {
            let input_format = formats::match_path(&input_format).spec();
            if input_format != self.format {
                self.dump(None, None).await?
            } else {
                self.content.clone()
            }
        } else {
            self.content.clone()
        };

        fs::write(&self.path, content_to_write.as_bytes())?;
        self.status = DocumentStatus::Synced;
        *self.last_write.write().await = Instant::now();

        Ok(())
    }

    /// Write the document to the file system, as an another file, possibly in
    /// another format.
    ///
    /// # Arguments
    ///
    /// - `path`: the path for the new file.
    /// - `format`: the format to dump the content as; if not supplied assumed to be
    ///    the document's existing format.
    /// - `theme`: theme to apply to the new document (HTML and PDF only).
    ///
    /// Note: this does not change the `path`, `format` or `status` of the current
    /// document.
    #[tracing::instrument(skip(self, path))]
    pub async fn write_as<P: AsRef<Path>>(
        &self,
        path: P,
        format: Option<String>,
        theme: Option<String>,
    ) -> Result<()> {
        let path = path.as_ref();

        let format = format.unwrap_or_else(|| {
            path.extension().map_or_else(
                || self.format.extension.clone(),
                |ext| ext.to_string_lossy().to_string(),
            )
        });

        let mut options = codecs::EncodeOptions {
            standalone: true,
            theme,
            ..Default::default()
        };

        let root = &*self.root.read().await;
        codecs::to_path(root, path, Some(&format), Some(options)).await?;

        Ok(())
    }

    /// A background task to write the document to its path on request
    ///
    /// # Arguments
    ///
    /// - `root`: The root [`Node`] to write (will be read locked)
    ///
    /// - `path`: The filesystem path to write to
    ///
    /// - `format`: The format to write (defaults to the path extension)
    ///
    /// - `request_receiver`: The channel to receive [`WriteRequest`]s on
    ///
    /// - `response_sender`: The channel to send a [`Response`] on when each request if fulfilled
    async fn write_task(
        root: &Arc<RwLock<Node>>,
        last_write: &Arc<RwLock<Instant>>,
        path: &Path,
        format: Option<&str>,
        request_receiver: &mut mpsc::UnboundedReceiver<WriteRequest>,
        response_sender: &broadcast::Sender<Response>,
    ) {
        let duration = Duration::from_millis(Document::WRITE_DEBOUNCE_MILLIS);
        let mut write = false;
        loop {
            match tokio::time::timeout(duration, request_receiver.recv()).await {
                // Request received: record and continue to wait for timeout unless `when` is now
                Ok(Some(request)) => {
                    write = true;
                    if !matches!(request.when, When::Now) {
                        continue;
                    }
                }
                // Sender dropped: end of task
                Ok(None) => break,
                // Timeout so do the following with the last unhandled request, if any
                Err(..) => {}
            };

            if write {
                tracing::trace!("Writing document to `{}`", path.display());
                if let Err(error) =
                    codecs::to_path(root.read().await.deref(), path, format, None).await
                {
                    tracing::error!("While writing to `{}`: {}", path.display(), error);
                }

                *last_write.write().await = Instant::now();
                write = false;
            }
        }
    }

    /// Dump the document's content to a string in its current, or
    /// alternative, format.
    ///
    /// # Arguments
    ///
    /// - `format`: the format to dump the content as; if not supplied assumed to be
    ///    the document's existing format.
    ///
    /// - `node_id`: the id of the node within the document to dump
    #[tracing::instrument(skip(self))]
    pub async fn dump(&self, format: Option<String>, node_id: Option<String>) -> Result<String> {
        let format = match format {
            Some(format) => format,
            None => return Ok(self.content.clone()),
        };

        let root = &*self.root.read().await;
        if let Some(node_id) = node_id {
            let address = self.addresses.read().await.get(&node_id).cloned();
            let pointer = resolve(root, address, Some(node_id))?;
            let node = pointer.to_node()?;
            codecs::to_string(&node, &format, None).await
        } else {
            codecs::to_string(root, &format, None).await
        }
    }

    /// Load content into the document
    ///
    /// If the format of the new content is different to the document's format
    /// then the content will be converted to the document's format.
    ///
    /// # Arguments
    ///
    /// - `content`: the content to load into the document
    /// - `format`: the format of the content; if not supplied assumed to be
    ///    the document's existing format.
    #[tracing::instrument(skip(self, content))]
    pub async fn load(&mut self, content: String, format: Option<String>) -> Result<()> {
        let mut decode_content = true;
        if let Some(format) = format {
            let other_format = formats::match_path(&format).spec();
            if other_format != self.format {
                let node = codecs::from_str(&content, &other_format.extension, None).await?;
                if !self.format.binary {
                    self.content = codecs::to_string(&node, &self.format.extension, None).await?;
                }
                let mut root = &mut *self.root.write().await;
                *root = node;
                decode_content = false;
            } else {
                self.content = content;
            }
        } else {
            self.content = content;
        };
        self.status = DocumentStatus::Unwritten;

        self.update(decode_content).await
    }

    /// Generate a [`Patch`] describing the operations needed to modify this
    /// document so that it is equal to another.
    #[tracing::instrument(skip(self, other))]
    pub async fn diff(&self, other: &Document) -> Result<Patch> {
        let me = &*self.root.read().await;
        let other = &*other.root.read().await;
        let patch = diff(me, other);
        Ok(patch)
    }

    /// Merge changes from two or more derived version into this document.
    ///
    /// See documentation on the [`merge`] function for how any conflicts
    /// are resolved.
    #[tracing::instrument(skip(self, deriveds))]
    pub async fn merge(&mut self, deriveds: &[Document]) -> Result<()> {
        let mut guard = self.root.write().await;

        // Need to store `let` bindings to read guards before dereferencing them
        let mut guards = Vec::new();
        for derived in deriveds {
            let guard = derived.root.read().await;
            guards.push(guard)
        }
        let others: Vec<&Node> = guards.iter().map(|guard| guard.deref()).collect();

        // Do the merge into root
        merge(&mut *guard, &others);

        // TODO updating of *content from root* and publishing of events etc needs to be sorted out
        if !self.format.binary {
            self.content = codecs::to_string(&*guard, &self.format.extension, None).await?;
        }

        // Drop root guard to allow update
        drop(guard);

        self.update(false).await?;

        Ok(())
    }

    /// A background task to patch the root node of the document on request
    ///
    /// Use an unbounded channel for sending patches, so that sending threads never
    /// block (if there are lots of patches) and thereby hold on to locks causing a
    /// deadlock.
    ///
    /// # Arguments
    ///
    /// - `id`: The id of the document (used in the published event topic)
    ///
    /// - `root`: The root [`Node`] to apply the patch to (will be write locked)
    ///
    /// - `addresses`: The [`AddressMap`] to use to locate nodes within the root
    ///                node (will be read locked)
    ///
    /// - `compile_sender`: The channel to send any [`CompileRequest`]s after a patch is applied
    ///
    /// - `write_sender`: The channel to send any [`WriteRequest`]s after a patch is applied
    ///
    /// - `request_receiver`: The channel to receive [`PatchRequest`]s on
    ///
    /// - `response_sender`: The channel to send a [`Response`] on when each request if fulfilled
    async fn patch_task(
        id: &str,
        root: &Arc<RwLock<Node>>,
        addresses: &Arc<RwLock<AddressMap>>,
        compile_sender: &mpsc::Sender<CompileRequest>,
        write_sender: &mpsc::UnboundedSender<WriteRequest>,
        request_receiver: &mut mpsc::UnboundedReceiver<PatchRequest>,
        response_sender: &broadcast::Sender<Response>,
    ) {
        let mut counter = 0u32;
        while let Some(request) = request_receiver.recv().await {
            tracing::trace!(
                "Patching document `{}` for requests `{}`",
                &id,
                request.ids.iter().join(",")
            );

            let mut patch = request.patch;
            let start = patch.target.clone();

            // If the patch is empty then continue early rather than obtain locks etc
            if patch.is_empty() {
                continue;
            }

            // Block to ensure locks are retained for only as long as needed
            {
                let root = &mut *root.write().await;
                let addresses = &*addresses.read().await;

                // If the patch has a `target` but no `address` then use `address_map` to populate the address
                // for faster patch application.
                if let (None, Some(node_id)) = (&patch.address, &patch.target) {
                    if let Some(address) = addresses.get(node_id) {
                        patch.address = Some(address.clone());
                    }
                }

                // Apply the patch to the root node
                apply(root, &patch);

                // Pre-publish the patch
                counter += 1;
                patch.prepublish(counter, root);
            }

            // Publish the patch
            publish(
                &["documents:", id, ":patched"].concat(),
                &DocumentEvent {
                    type_: DocumentEventType::Patched,
                    patch: Some(patch),
                },
            );

            // Possibly compile, execute, and/or write; or respond
            if !matches!(request.compile, When::Never) {
                tracing::trace!(
                    "Sending compile request for document `{}` for patch requests `{}`",
                    &id,
                    request.ids.iter().join(",")
                );
                if let Err(error) = compile_sender
                    .send(CompileRequest::new(
                        request.ids,
                        request.compile,
                        request.execute,
                        request.write,
                        start,
                    ))
                    .await
                {
                    tracing::error!(
                        "While sending compile request for document `{}`: {}",
                        id,
                        error
                    );
                }
            } else if !matches!(request.write, When::Never) {
                tracing::trace!(
                    "Sending write request for document `{}` for patch requests `{}`",
                    &id,
                    request.ids.iter().join(",")
                );
                if let Err(error) = write_sender.send(WriteRequest::new(request.ids, request.write))
                {
                    tracing::error!(
                        "While sending write request for document `{}`: {}",
                        id,
                        error
                    );
                }
            } else {
                for request_id in request.ids {
                    if let Err(error) = response_sender.send(Response::new(request_id)) {
                        tracing::debug!(
                            "While sending response for document `{}` from patch task: {}",
                            id,
                            error
                        );
                    }
                }
            }
        }
    }

    /// Request that a [`Patch`] be applied to the root node of the document
    ///
    /// # Arguments
    ///
    /// - `patch`: The patch to apply
    ///
    /// - `compile`: Should the document be compiled after the patch is applied?
    ///
    /// - `execute`: Should the document be executed after the patch is applied?
    ///              If the patch as a `target` then the document will be executed from that
    ///              node, otherwise the entire document will be executed.
    /// - `write`: Should the document be written after the patch is applied?
    #[tracing::instrument(skip(self, patch))]
    pub async fn patch_request(
        &self,
        patch: Patch,
        assemble: When,
        compile: When,
        execute: When,
        write: When,
    ) -> Result<RequestId> {
        tracing::debug!("Sending patch request for document `{}`", self.id);

        let request_id = RequestId::new();
        let request = PatchRequest::new(
            vec![request_id.clone()],
            patch,
            When::Now,
            assemble,
            compile,
            execute,
            write,
        );
        if let Err(error) = self.patch_request_sender.send(request) {
            bail!(
                "When sending patch request for document `{}`: {}",
                self.id,
                error
            )
        };

        Ok(request_id)
    }

    /// Patch the document
    #[tracing::instrument(skip(self))]
    pub async fn patch(
        &mut self,
        patch: Patch,
        assemble: When,
        compile: When,
        execute: When,
        write: When,
    ) -> Result<()> {
        let request_id = self
            .patch_request(patch, assemble, compile, execute, write)
            .await?;

        tracing::trace!(
            "Waiting for patch response for document `{}` for request `{}`",
            self.id,
            request_id
        );
        while let Ok(response) = self.response_receiver.recv().await {
            if response.request_id == request_id {
                tracing::trace!(
                    "Received patch response for document `{}` for request `{}`",
                    self.id,
                    request_id
                );
                break;
            }
        }

        Ok(())
    }

    /// A background task to assemble the root node of the document on request
    ///
    /// # Arguments
    ///
    /// - `id`: The id of the document
    ///
    /// - `path`: The path of the document to be assembled
    ///
    /// - `project`: The project of the document to be assembled
    ///
    /// - `root`: The root [`Node`] to apply the compilation patch to
    ///
    /// - `addresses`: The [`AddressMap`] to be updated
    ///
    /// - `call_docs`:  The [`CallableMap`] of `Document` for each `Call` to be updated
    ///
    /// - `patch_sender`: A [`PatchRequest`] channel to send patches describing the changes to
    ///                   assembled nodes
    ///
    /// - `compile_sender`: A [`CompileRequest`] channel to send any requests to compile the
    ///                     document after it has been assembled
    ///
    /// - `execute_sender`: An [`ExecuteRequest`] channel to send any requests to execute the
    ///                     document after it has been assembled
    ///
    /// - `write_sender`: The channel to send any [`WriteRequest`]s after a patch is applied
    ///
    /// - `request_receiver`: The channel to receive [`AssembleRequest`]s on
    ///
    /// - `response_sender`: The channel to send a [`Response`] on when each request if fulfilled
    #[allow(clippy::too_many_arguments)]
    pub async fn assemble_task(
        id: &str,
        path: &Path,
        project: &Path,
        root: &Arc<RwLock<Node>>,
        address_map: &Arc<RwLock<AddressMap>>,
        call_docs: &Arc<RwLock<CallDocuments>>,
        patch_sender: &mpsc::UnboundedSender<PatchRequest>,
        compile_sender: &mpsc::Sender<CompileRequest>,
        execute_sender: &mpsc::Sender<ExecuteRequest>,
        write_sender: &mpsc::UnboundedSender<WriteRequest>,
        request_receiver: &mut mpsc::Receiver<AssembleRequest>,
        response_sender: &broadcast::Sender<Response>,
    ) {
        let duration = Duration::from_millis(Document::ASSEMBLE_DEBOUNCE_MILLIS);
        let mut request_ids = Vec::new();
        let mut compile = When::Never;
        let mut execute = When::Never;
        let mut write = When::Never;
        loop {
            match tokio::time::timeout(duration, request_receiver.recv()).await {
                // Request received: record and continue to wait for timeout unless `when` is now
                Ok(Some(mut request)) => {
                    if !matches!(request.when, When::Never) {
                        request_ids.append(&mut request.ids);

                        compile.no_later_than(request.compile);
                        execute.no_later_than(request.execute);
                        write.no_later_than(request.write);

                        if !matches!(request.when, When::Now) {
                            continue;
                        }
                    }
                }
                // Sender dropped: end of task
                Ok(None) => break,
                // Timeout so do the following with the last unhandled request, if any
                Err(..) => {}
            };

            if request_ids.is_empty() {
                continue;
            }

            tracing::trace!(
                "Assembling document `{}` for requests `{}`",
                id,
                request_ids.iter().join(",")
            );

            // Assemble the root node
            match assemble(path, root, call_docs, patch_sender).await {
                Ok(new_address_map) => {
                    // Update the address map
                    *address_map.write().await = new_address_map;

                    /*
                    // Ensure that each `Call` node has a `Document` for when it is executed
                    let mut call_docs = call_docs.write().await;
                    for (call_id, (doc_path, doc_format)) in call_map {
                        let signature = [
                            doc_path.to_string_lossy().as_ref(),
                            doc_format.as_deref().unwrap_or(""),
                        ]
                        .concat();
                        if !call_docs.has_signature(&call_id, &signature) {
                            let callable =
                                Box::new(Document::open(doc_path, doc_format).await.unwrap());
                            call_docs.insert(call_id, signature, callable);
                        }
                    }
                    */
                }
                Err(error) => tracing::error!("While assembling document `{}`: {}", id, error),
            };

            // Possibly compile, execute, and/or write; or respond
            if !matches!(compile, When::Never) {
                tracing::trace!(
                    "Sending compile request for document `{}` for assemble requests `{}`",
                    &id,
                    request_ids.iter().join(",")
                );
                if let Err(error) = compile_sender
                    .send(CompileRequest::new(
                        request_ids.clone(),
                        compile,
                        execute,
                        write,
                        None,
                    ))
                    .await
                {
                    tracing::error!(
                        "While sending execute request for document `{}`: {}",
                        id,
                        error
                    );
                }
            } else if !matches!(execute, When::Never) {
                tracing::trace!(
                    "Sending compile request for document `{}` for assemble requests `{}`",
                    &id,
                    request_ids.iter().join(",")
                );
                if let Err(error) = execute_sender
                    .send(ExecuteRequest::new(
                        request_ids.clone(),
                        execute,
                        write,
                        None,
                        None,
                        None,
                    ))
                    .await
                {
                    tracing::error!(
                        "While sending execute request for document `{}`: {}",
                        id,
                        error
                    );
                }
            } else if !matches!(write, When::Never) {
                tracing::trace!(
                    "Sending write request for document `{}` for assemble requests `{}`",
                    &id,
                    request_ids.iter().join(",")
                );
                if let Err(error) = write_sender.send(WriteRequest::new(request_ids.clone(), write))
                {
                    tracing::error!(
                        "While sending write request for document `{}`: {}",
                        id,
                        error
                    );
                }
            } else {
                for request_id in &request_ids {
                    if let Err(error) = response_sender.send(Response::new(request_id.clone())) {
                        tracing::debug!(
                            "While sending response for document `{}` from assemble task: {}",
                            id,
                            error
                        );
                    }
                }
            }

            request_ids.clear();
            compile = When::Never;
            execute = When::Never;
            write = When::Never;
        }
    }

    /// Request that the the document be assembled
    #[tracing::instrument(skip(self))]
    pub async fn assemble_request(
        &self,
        compile: When,
        execute: When,
        write: When,
    ) -> Result<RequestId> {
        tracing::debug!("Sending assemble request for document `{}`", self.id);

        let request_id = RequestId::new();
        let request =
            AssembleRequest::new(vec![request_id.clone()], When::Now, compile, execute, write);
        if let Err(error) = self.assemble_request_sender.send(request).await {
            bail!(
                "When sending assemble request for document `{}`: {}",
                self.id,
                error
            )
        };

        Ok(request_id)
    }

    /// Assemble the document
    #[tracing::instrument(skip(self))]
    pub async fn assemble(&mut self, compile: When, execute: When, write: When) -> Result<()> {
        let request_id = self.assemble_request(compile, execute, write).await?;

        tracing::trace!(
            "Waiting for assemble response for document `{}` for request `{}`",
            self.id,
            request_id
        );
        while let Ok(response) = self.response_receiver.recv().await {
            if response.request_id == request_id {
                tracing::trace!(
                    "Received assemble response for document `{}` for request `{}`",
                    self.id,
                    request_id
                );
                break;
            }
        }

        Ok(())
    }

    /// A background task to compile the root node of the document on request
    ///
    /// # Arguments
    ///
    /// - `id`: The id of the document
    ///
    /// - `path`: The path of the document to be compiled
    ///
    /// - `project`: The project of the document to be compiled
    ///
    /// - `root`: The root [`Node`] to apply the compilation patch to
    ///
    /// - `addresses`: The [`AddressMap`] to be updated
    ///
    /// - `tags`: The document's global [`TagMap`] to be updated
    ///
    /// - `graph`:  The [`Graph`] to be updated
    ///
    /// - `patch_sender`: A [`PatchRequest`] channel to send patches describing the changes to
    ///                   compiled nodes
    ///
    /// - `execute_sender`: An [`ExecuteRequest`] channel to send any requests to execute the
    ///                     document after it has been compiled
    ///
    /// - `write_sender`: The channel to send any [`WriteRequest`]s after a patch is applied
    ///
    /// - `request_receiver`: The channel to receive [`CompileRequest`]s on
    ///
    /// - `response_sender`: The channel to send a [`Response`] on when each request if fulfilled
    #[allow(clippy::too_many_arguments)]
    pub async fn compile_task(
        id: &str,
        path: &Path,
        project: &Path,
        root: &Arc<RwLock<Node>>,
        addresses: &Arc<RwLock<AddressMap>>,
        tags: &Arc<RwLock<TagMap>>,
        graph: &Arc<RwLock<Graph>>,
        patch_sender: &mpsc::UnboundedSender<PatchRequest>,
        execute_sender: &mpsc::Sender<ExecuteRequest>,
        write_sender: &mpsc::UnboundedSender<WriteRequest>,
        request_receiver: &mut mpsc::Receiver<CompileRequest>,
        response_sender: &broadcast::Sender<Response>,
    ) {
        let duration = Duration::from_millis(Document::COMPILE_DEBOUNCE_MILLIS);
        let mut request_ids = Vec::new();
        let mut execute = When::Never;
        let mut write = When::Never;
        loop {
            match tokio::time::timeout(duration, request_receiver.recv()).await {
                // Request received: record and continue to wait for timeout unless `when` is now
                Ok(Some(mut request)) => {
                    if !matches!(request.when, When::Never) {
                        request_ids.append(&mut request.ids);

                        execute.no_later_than(request.execute);
                        write.no_later_than(request.write);

                        if !matches!(request.when, When::Now) {
                            continue;
                        }
                    }
                }
                // Sender dropped: end of task
                Ok(None) => break,
                // Timeout so do the following with the last unhandled request, if any
                Err(..) => {}
            };

            if request_ids.is_empty() {
                continue;
            }

            tracing::trace!(
                "Compiling document `{}` for requests `{}`",
                id,
                request_ids.iter().join(",")
            );

            // Compile the root node
            match compile(path, project, root, addresses, tags, patch_sender).await {
                Ok(new_graph) => {
                    *graph.write().await = new_graph;
                }
                Err(error) => tracing::error!("While compiling document `{}`: {}", id, error),
            }

            // Possibly execute and/or write; or respond
            if !matches!(execute, When::Never) {
                tracing::trace!(
                    "Sending execute request for document `{}` for compile requests `{}`",
                    &id,
                    request_ids.iter().join(",")
                );
                if let Err(error) = execute_sender
                    .send(ExecuteRequest::new(
                        request_ids.clone(),
                        When::Soon,
                        When::Soon,
                        None,
                        None,
                        None,
                    ))
                    .await
                {
                    tracing::error!(
                        "While sending execute request for document `{}`: {}",
                        id,
                        error
                    );
                }
            } else if !matches!(write, When::Never) {
                tracing::trace!(
                    "Sending write request for document `{}` for compile requests `{}`",
                    &id,
                    request_ids.iter().join(",")
                );
                if let Err(error) =
                    write_sender.send(WriteRequest::new(request_ids.clone(), When::Soon))
                {
                    tracing::error!(
                        "While sending write request for document `{}`: {}",
                        id,
                        error
                    );
                }
            } else {
                for request_id in &request_ids {
                    if let Err(error) = response_sender.send(Response::new(request_id.clone())) {
                        tracing::debug!(
                            "While sending response for document `{}` from compile task: {}",
                            id,
                            error
                        );
                    }
                }
            }

            request_ids.clear();
            execute = When::Never;
            write = When::Never;
        }
    }

    /// Request that the the document be compiled
    #[tracing::instrument(skip(self))]
    pub async fn compile_request(
        &self,
        execute: When,
        write: When,
        start: Option<String>,
    ) -> Result<RequestId> {
        tracing::debug!("Sending compile request for document `{}`", self.id);

        let request_id = RequestId::new();
        let request =
            CompileRequest::new(vec![request_id.clone()], When::Now, execute, write, start);
        if let Err(error) = self.compile_request_sender.send(request).await {
            bail!(
                "When sending compile request for document `{}`: {}",
                self.id,
                error
            )
        };

        Ok(request_id)
    }

    /// Compile the document
    ///
    /// This method is the same as `compile_request` but will wait for the compilation to finish
    /// before returning. This is useful in some circumstances, such as ensuring the document
    /// is compiled before HTML is encoded for it on initial opening.
    #[tracing::instrument(skip(self))]
    pub async fn compile(
        &mut self,
        execute: When,
        write: When,
        start: Option<String>,
    ) -> Result<()> {
        let request_id = self.compile_request(execute, write, start).await?;

        tracing::trace!(
            "Waiting for compile response for document `{}` for request `{}`",
            self.id,
            request_id
        );
        while let Ok(response) = self.response_receiver.recv().await {
            if response.request_id == request_id {
                tracing::trace!(
                    "Received compile response for document `{}` for request `{}`",
                    self.id,
                    request_id
                );
                break;
            }
        }

        Ok(())
    }

    /// A background task to execute the root node of the document on request
    ///
    /// # Arguments
    ///
    /// - `id`: The id of the document
    ///
    /// - `path`: The path of the document to be compiled
    ///
    /// - `project`: The project of the document to be compiled
    ///
    /// - `root`: The root [`Node`] to apply the compilation patch to
    ///
    /// - `addresses`: The [`AddressMap`] to be updated
    ///
    /// - `tags`: The document's global [`TagMap`] for passing tags on to executed nodes
    ///
    /// - `graph`:  The [`Graph`] to be updated
    ///
    /// - `kernel_space`:  The [`KernelSpace`] to use for execution
    ///
    /// - `call_docs`:  The [`Document`]s to call for each `Call` node
    ///
    /// - `patch_sender`: A [`PatchRequest`] channel sender to send patches describing the changes to
    ///                   executed nodes
    ///
    /// - `write_sender`: The channel to send any [`WriteRequest`]s on
    ///
    /// - `cancel_receiver`: The channel to receive [`CancelRequest`]s on
    ///
    /// - `request_receiver`: The channel to receive [`ExecuteRequest`]s on
    ///
    /// - `response_sender`: The channel to send a [`Response`] on when each request if fulfilled
    #[allow(clippy::too_many_arguments)]
    pub async fn execute_task(
        id: &str,
        path: &Path,
        project: &Path,
        root: &Arc<RwLock<Node>>,
        addresses: &Arc<RwLock<AddressMap>>,
        tags: &Arc<RwLock<TagMap>>,
        graph: &Arc<RwLock<Graph>>,
        kernel_space: &Arc<RwLock<KernelSpace>>,
        call_docs: &Arc<RwLock<CallDocuments>>,
        patch_sender: &mpsc::UnboundedSender<PatchRequest>,
        write_sender: &mpsc::UnboundedSender<WriteRequest>,
        cancel_receiver: &mut mpsc::Receiver<CancelRequest>,
        request_receiver: &mut mpsc::Receiver<ExecuteRequest>,
        response_sender: &broadcast::Sender<Response>,
    ) {
        let duration = Duration::from_millis(Document::EXECUTE_DEBOUNCE_MILLIS);
        let mut request_ids = Vec::new();
        let mut start = None;
        let mut ordering = PlanOptions::default_ordering();
        let mut max_concurrency = PlanOptions::default_max_concurrency();
        let mut write = When::Never;
        loop {
            match tokio::time::timeout(duration, request_receiver.recv()).await {
                // Request received: record and continue to wait for timeout unless `now` is true
                Ok(Some(mut request)) => {
                    if !matches!(request.when, When::Never) {
                        request_ids.append(&mut request.ids);

                        // In the following, we allow more 'conservative' execution options to
                        // override the default or those in previous requests.

                        // Precedence for executing whole document, rather than starting at a node
                        // If there is only one request then use its start, otherwise execute the whole document.
                        if request_ids.len() == 1 {
                            start = request.start;
                        } else {
                            start = None;
                        }

                        // Precedence for appearance, over topological, over single ordering
                        if let Some(request_ordering) = request.ordering {
                            use PlanOrdering::*;
                            match (ordering, request_ordering) {
                                (Single, Topological | Appearance) | (Topological, Appearance) => {
                                    ordering = request_ordering;
                                }
                                _ => {}
                            }
                        }

                        // Precedence for lowest concurrency
                        if let Some(request_concurrency) = request.max_concurrency {
                            if request_concurrency < max_concurrency {
                                max_concurrency = request_concurrency;
                            }
                        }

                        write.no_later_than(request.write);

                        if !matches!(request.when, When::Now) {
                            continue;
                        }
                    }
                }
                // Sender dropped: end of task
                Ok(None) => break,
                // Timeout so do the following with the last unhandled request, if any
                Err(..) => {}
            };

            if request_ids.is_empty() {
                continue;
            }

            tracing::trace!(
                "Executing document `{}` for requests `{}`",
                &id,
                request_ids.iter().join(",")
            );

            // Generate the execution plan
            let start = start
                .clone()
                .map(|node_id| resources::code(path, &node_id, "", None));
            let tags_guard = tags.read().await;
            let plan = match graph
                .read()
                .await
                .plan(
                    start,
                    None,
                    Some(&*tags_guard),
                    Some(PlanOptions {
                        ordering,
                        max_concurrency,
                    }),
                )
                .await
            {
                Ok(plan) => plan,
                Err(error) => {
                    tracing::error!("While generating execution plan: {}", error);
                    continue;
                }
            };
            drop(tags_guard);

            // Execute the plan on the root node
            execute(
                &plan,
                root,
                addresses,
                tags,
                kernel_space,
                call_docs,
                patch_sender,
                cancel_receiver,
            )
            .await;

            // Possibly write document; or respond
            if !matches!(write, When::Never) {
                tracing::trace!(
                    "Sending write request for document `{}` for requests `{}`",
                    &id,
                    request_ids.iter().join(",")
                );
                if let Err(error) = write_sender.send(WriteRequest::new(request_ids.clone(), write))
                {
                    tracing::error!(
                        "While sending write request for document `{}`: {}",
                        id,
                        error
                    );
                }
            } else {
                for request_id in &request_ids {
                    if let Err(error) = response_sender.send(Response::new(request_id.clone())) {
                        tracing::debug!(
                            "While sending response for document `{}` from execute task: {}",
                            id,
                            error
                        );
                    }
                }
            }

            request_ids.clear();
            write = When::Never;
        }
    }

    /// Request that the document be executed
    #[tracing::instrument(skip(self))]
    pub async fn execute_request(
        &self,
        write: When,
        start: Option<String>,
        ordering: Option<PlanOrdering>,
        max_concurrency: Option<usize>,
    ) -> Result<RequestId> {
        tracing::debug!("Sending execute request for document `{}`", self.id);

        let request_id = RequestId::new();
        let request = ExecuteRequest::new(
            vec![request_id.clone()],
            When::Now,
            write,
            start,
            ordering,
            max_concurrency,
        );
        if let Err(error) = self.execute_request_sender.send(request).await {
            bail!(
                "When sending execute request for document `{}`: {}",
                self.id,
                error
            )
        };

        Ok(request_id)
    }

    /// Execute the document
    ///
    /// This method is the same as `execute_request` but will wait for the execution to finish
    /// before returning. This is useful in some circumstances, such as ensuring the document
    /// is executed before saving it to file.
    #[tracing::instrument(skip(self))]
    pub async fn execute(
        &mut self,
        write: When,
        start: Option<String>,
        ordering: Option<PlanOrdering>,
        max_concurrency: Option<usize>,
    ) -> Result<()> {
        // Execute the document. Do not write now; maybe at end of this func.
        let request_id = self
            .execute_request(When::Never, start, ordering, max_concurrency)
            .await?;

        // Wait for execution to finish
        tracing::trace!(
            "Waiting for execute response for document `{}` for request `{}`",
            self.id,
            request_id
        );
        while let Ok(response) = self.response_receiver.recv().await {
            if response.request_id == request_id {
                tracing::trace!(
                    "Received execute response for document `{}` for request `{}`",
                    self.id,
                    request_id
                );
                break;
            }
        }

        // Recompile the document to ensure properties such as `code_dependencies` reflect the
        // new state of the document, and write if necessary
        self.compile(When::Never, write, None).await?;

        Ok(())
    }

    /// React to a change in a file path
    ///
    /// If the path corresponds to a `File` resource in the document's graph then re-compile,
    /// and potentially re-execute, and write the document.
    async fn react(&mut self, path: &Path) {
        let graph = self.graph.read().await;
        if let Ok(resource_info) = graph.find_resource_info(&resources::file(path)) {
            // Only execute and write if a code related resource e.g. `CodeChunk` and
            // just compile for others e.g. `Include`
            let mut assemble = When::Never;
            let mut compile = When::Never;
            let mut execute = When::Never;
            let mut write = When::Never;
            for dependent in resource_info.dependents.iter().flatten() {
                if let Resource::Node(resources::Node { kind, .. }) = dependent {
                    if kind == "Include" {
                        assemble.no_later_than(When::Now);
                        compile.no_later_than(When::Now);
                    }
                } else if matches!(dependent, Resource::Code(..)) {
                    compile.no_later_than(When::Now);
                    execute.no_later_than(When::Now);
                    write.no_later_than(When::Soon);
                }
            }

            tracing::trace!(
                "Document `{}` reacting because file changed: {}",
                self.id,
                path.display()
            );
            let result = if !matches!(assemble, When::Never) {
                self.assemble_request(compile, execute, write).await
            } else if !matches!(compile, When::Never) {
                self.compile_request(execute, write, None).await
            } else if !matches!(execute, When::Never) {
                self.execute_request(write, None, None, None).await
            } else {
                return;
            };

            if let Err(error) = result {
                tracing::error!("When sending request for document `{}`: {}", self.id, error);
            }
        }
    }

    /// Get the parameters of the document
    pub async fn params(&mut self) -> Result<IndexMap<String, (String, Address, Parameter)>> {
        // Assemble the document to ensure its `addresses` are up to date
        self.assemble(When::Never, When::Never, When::Never).await?;

        // Collect parameters from addresses
        let addresses = self.addresses.read().await;
        let root = &*self.root.read().await;
        let params = addresses
            .iter()
            .filter_map(|(id, address)| {
                if let Ok(pointer) = resolve(root, Some(address.clone()), Some(id.clone())) {
                    if let Some(InlineContent::Parameter(param)) = pointer.as_inline() {
                        // Exclude parameters that `Call` arguments and which have an id that starts with "ar-".
                        if id.starts_with("ar-") {
                            return None;
                        }
                        return Some((
                            param.name.clone(),
                            (id.clone(), address.clone(), param.clone()),
                        ));
                    }
                }
                None
            })
            .collect();

        Ok(params)
    }

    /// Call the document with a set of parameters
    pub async fn call(&mut self, args: HashMap<String, String>) -> Result<()> {
        // Get the document's params
        let mut params = self.params().await?;

        // Attempt to set params based on args
        {
            let root = &mut *self.root.write().await;
            for (name, value) in args {
                if let Some((id, address, param)) = params.remove(&name) {
                    if let Some(validator) = param.validator.as_deref() {
                        match validator.parse(&value) {
                            Ok(value) => {
                                if let Ok(mut pointer) = resolve_mut(root, Some(address), Some(id))
                                {
                                    if let Some(InlineContent::Parameter(param)) =
                                        pointer.as_inline_mut()
                                    {
                                        param.value = Some(Box::new(value));
                                    }
                                }
                            }
                            Err(error) => bail!(
                                "While attempting to parse document parameter `{}`: {}",
                                name,
                                error
                            ),
                        }
                    }
                } else {
                    bail!("Document does not have a parameter named `{}`", name)
                }
            }
        }

        // Now execute the document
        self.execute(When::Never, None, None, None).await?;

        Ok(())
    }

    /// Cancel the execution of the document
    ///
    /// # Arguments
    ///
    /// - `start`: The node whose execution should be cancelled.
    ///
    /// - `scope`: The scope of the cancellation (the `Single` node identified
    ///            by `start` or `All` nodes in the current plan).
    #[tracing::instrument(skip(self))]
    pub async fn cancel(
        &self,
        start: Option<String>,
        scope: Option<PlanScope>,
    ) -> Result<RequestId> {
        tracing::debug!("Cancelling execution of document `{}`", self.id);

        let request_id = RequestId::new();
        let request = CancelRequest::new(vec![request_id.clone()], start, scope);
        self.cancel_request_sender.send(request).await.or_else(|_| {
            bail!(
                "When sending cancel request for document `{}`: the receiver has dropped",
                self.id
            )
        });

        Ok(request_id)
    }

    /// Restart a kernel (or all kernels) in the document's kernel space
    ///
    /// Cancels any execution plan that is running, destroy the document's
    /// existing kernel, and create's a new one
    #[tracing::instrument(skip(self))]
    pub async fn restart(&self, kernel_id: Option<String>) -> Result<()> {
        tracing::debug!("Restarting kernel/s for document `{}`", self.id);

        self.cancel(None, Some(PlanScope::All)).await;

        let kernels = &*self.kernels.write().await;
        kernels.restart(kernel_id).await?;

        Ok(())
    }

    /// Get the list of kernels in the document's kernel space
    pub async fn kernels(&self) -> KernelInfos {
        let kernel_space = &*self.kernels.read().await;
        kernel_space.kernels().await
    }

    /// Get the list of symbols in the document's kernel space
    pub async fn symbols(&self) -> KernelSymbols {
        let kernel_space = &*self.kernels.read().await;
        kernel_space.symbols().await
    }

    /// Update the `root` (and associated properties) of the document and publish updated encodings
    ///
    /// Publishes `encoded:` events for each of the formats subscribed to.
    /// Error results from this function (e.g. compile errors)
    /// should generally not be bubbled up.
    ///
    /// # Arguments
    ///
    /// - `decode_content`: Should the current content of the be decoded?. This
    ///                     is an optimization for situations where the `root` has
    ///                     just been decoded from the current `content`.
    #[tracing::instrument(skip(self))]
    async fn update(&mut self, decode_content: bool) -> Result<()> {
        tracing::debug!(
            "Updating document `{}` at `{}`",
            self.id,
            self.path.display()
        );

        // Decode the binary file or, in-memory content into the `root` node
        // of the document
        let format = &self.format.extension;
        let mut root = if self.format.binary {
            if self.path.exists() {
                tracing::debug!("Decoding document `{}` root from path", self.id);
                codecs::from_path(&self.path, Some(format), None).await?
            } else {
                self.root.read().await.clone()
            }
        } else if !self.content.is_empty() {
            if decode_content {
                tracing::debug!("Decoding document `{}` root from content", self.id);
                codecs::from_str(&self.content, format, None).await?
            } else {
                self.root.read().await.clone()
            }
        } else {
            tracing::debug!("Setting document `{}` root to empty article", self.id);
            Node::Article(Article::default())
        };

        // Reshape the `root`
        // TODO: Pass user options for reshaping through
        reshape(&mut root, None)?;

        // Determine if the document is preview-able, based on the type of the root
        // This list of types should be updated as HTML encoding is implemented for each.
        self.previewable = matches!(
            root,
            Node::Article(..)
                | Node::ImageObject(..)
                | Node::AudioObject(..)
                | Node::VideoObject(..)
        );

        // Set the root, assemble and compile
        // TODO: Reconsider this in refactoring of alternative format representations of docs
        *self.root.write().await = root;
        self.assemble(When::Now, When::Never, When::Never).await?;

        // Publish any events for which there are subscriptions (this will probably go elsewhere)
        for subscription in self.subscriptions.keys() {
            // Encode the `root` into each of the formats for which there are subscriptions
            if let Some(format) = subscription.strip_prefix("encoded:") {
                tracing::debug!("Encoding document `{}` to format `{}`", self.id, format);
                match codecs::to_string(&*self.root.read().await, format, None).await {
                    Ok(content) => {
                        self.publish(
                            DocumentEventType::Encoded,
                            Some(content),
                            Some(format.into()),
                        );
                    }
                    Err(error) => {
                        tracing::warn!("Unable to encode to format `{}`: {}", format, error)
                    }
                }
            }
        }

        Ok(())
    }

    /// Detect entities within the document
    pub async fn detect(&self) -> Result<Vec<DetectItem>> {
        let root = &*self.root.read().await;
        providers::detect(root).await
    }

    /// Generate a topic string for the document
    pub fn topic(&self, subtopic: &str) -> String {
        ["documents:", &self.id, ":", subtopic].concat()
    }

    /// Subscribe a client to one of the document's topics
    pub fn subscribe(&mut self, topic: &str, client: &str) -> String {
        match self.subscriptions.entry(topic.into()) {
            Entry::Occupied(mut occupied) => {
                occupied.get_mut().insert(client.into());
            }
            Entry::Vacant(vacant) => {
                vacant.insert(hashset! {client.into()});
            }
        }
        self.topic(topic)
    }

    /// Unsubscribe a client from one of the document's topics
    pub fn unsubscribe(&mut self, topic: &str, client: &str) -> String {
        if let Entry::Occupied(mut occupied) = self.subscriptions.entry(topic.to_string()) {
            let subscribers = occupied.get_mut();
            subscribers.remove(client);
            if subscribers.is_empty() {
                occupied.remove();
            }
        }
        self.topic(topic)
    }

    /// Get the number of subscribers to one of the document's topics
    fn subscribers(&self, topic: &str) -> usize {
        if let Some(subscriptions) = self.subscriptions.get(topic) {
            subscriptions.len()
        } else {
            0
        }
    }

    /// Publish an event for this document
    fn publish(&self, type_: DocumentEventType, content: Option<String>, format: Option<String>) {
        let format = format.map(|name| formats::match_name(&name).spec());

        let subtopic = match type_ {
            DocumentEventType::Encoded => format!(
                "encoded:{}",
                format.map_or_else(|| "undef".to_string(), |format| format.extension)
            ),
            _ => type_.to_string(),
        };

        publish(
            &self.topic(&subtopic),
            &DocumentEvent { type_, patch: None },
        )
    }

    /// Called when the file is removed from the file system
    ///
    /// Sets `status` to `Deleted` and publishes a `Deleted` event so that,
    /// for example, a document's tab can be updated to indicate it is deleted.
    fn deleted(&mut self, path: PathBuf) {
        tracing::debug!(
            "Deleted event for document `{}` at `{}`",
            self.id,
            path.display()
        );

        self.status = DocumentStatus::Deleted;

        self.publish(DocumentEventType::Deleted, None, None)
    }

    /// Called when the file is renamed
    ///
    /// Changes the `path` and publishes a `Renamed` event so that, for example,
    /// a document's tab can be updated with the new file name.
    #[allow(dead_code)]
    fn renamed(&mut self, from: PathBuf, to: PathBuf) {
        tracing::debug!(
            "Renamed event for document `{}`: `{}` to `{}`",
            self.id,
            from.display(),
            to.display()
        );

        // If the document has been moved out of its project then we need to reassign `project`
        // (to ensure that files in the old project can not be linked to).
        if to.strip_prefix(&self.project).is_err() {
            self.project = match to.parent() {
                Some(path) => path.to_path_buf(),
                None => to.clone(),
            }
        }

        self.path = to;

        self.publish(DocumentEventType::Renamed, None, None)
    }

    /// Called when the file is modified
    ///
    /// Reads the file into `content` and emits a `Modified` event so that the user
    /// can be asked if they want to load the new content into editor, or overwrite with
    /// existing editor content.
    ///
    /// Will ignore any events within a small duration of `write()` being called to avoid
    /// reacting to file modifications initiated by this process
    async fn modified(&mut self, path: PathBuf) {
        if self.last_write.read().await.elapsed() < Duration::from_millis(Self::WRITE_MUTE_MILLIS) {
            return;
        }

        tracing::debug!(
            "Modified event for document `{}` at `{}`",
            self.id,
            path.display()
        );

        self.status = DocumentStatus::Unread;

        match self.read(false).await {
            Ok(content) => self.publish(
                DocumentEventType::Modified,
                Some(content),
                Some(self.format.extension.clone()),
            ),
            Err(error) => tracing::error!("While attempting to read modified file: {}", error),
        }
    }
}

#[derive(Debug)]
pub struct DocumentHandler {
    /// The document being handled.
    pub(crate) document: Arc<Mutex<Document>>,

    /// The event handler thread's join handle.
    ///
    /// Held so that when this handler is dropped, the
    /// event handler thread is aborted.
    handler: Option<JoinHandle<()>>,
}

impl Clone for DocumentHandler {
    fn clone(&self) -> Self {
        DocumentHandler {
            document: self.document.clone(),
            handler: None,
        }
    }
}

impl Drop for DocumentHandler {
    fn drop(&mut self) {
        match &self.handler {
            Some(handler) => handler.abort(),
            None => {}
        }
    }
}

impl DocumentHandler {
    /// Create a new document handler.
    ///
    /// # Arguments
    ///
    /// - `document`: The document that this handler is for.
    /// - `watch`: Whether to watch the document (e.g. not for temporary, new files)
    pub(crate) fn new(document: Document, watch: bool) -> DocumentHandler {
        let id = document.id.clone();
        let path = document.path.clone();

        let document = Arc::new(Mutex::new(document));
        let handler = if watch {
            let handler = DocumentHandler::watch(id, path, Arc::clone(&document));
            Some(handler)
        } else {
            None
        };

        DocumentHandler { document, handler }
    }

    const WATCHER_DELAY_MILLIS: u64 = 100;

    /// Watch the document.
    ///
    /// It is necessary to have a file watcher that is separate from a project directory watcher
    /// for documents that are opened independent of a project (a.k.a. orphan documents).
    ///
    /// It is also necessary for this watcher to be on the parent folder of the document
    /// (which, for some documents may be concurrent with the watcher for the project) and to filter
    /// events related to the file. That is necessary because some events are otherwise
    /// not captured e.g. file renames (delete and then create) and file writes by some software
    /// (e.g. LibreOffice deletes and then creates a file instead of just writing it).
    fn watch(id: String, path: PathBuf, document: Arc<Mutex<Document>>) -> JoinHandle<()> {
        let (async_sender, mut async_receiver) = tokio::sync::mpsc::channel(100);

        let path_cloned = path.clone();

        // Standard thread to run blocking sync file watcher
        std::thread::spawn(move || -> Result<()> {
            use notify::{watcher, RecursiveMode, Watcher};

            let (watcher_sender, watcher_receiver) = std::sync::mpsc::channel();
            let mut watcher = watcher(
                watcher_sender,
                Duration::from_millis(DocumentHandler::WATCHER_DELAY_MILLIS),
            )?;
            let parent = path.parent().unwrap_or(&path);
            watcher.watch(&parent, RecursiveMode::NonRecursive)?;

            // Event checking timeout. Can be quite long since only want to check
            // whether we can end this thread.
            let timeout = Duration::from_millis(100);

            let path_string = path.display().to_string();
            let span = tracing::info_span!("document_watch", path = path_string.as_str());
            let _enter = span.enter();
            tracing::trace!(
                "Starting document watcher for '{}' at '{}'",
                id,
                path_string
            );
            loop {
                // Check for an event. Use `recv_timeout` so we don't
                // get stuck here and will do following check that ends this
                // thread if the owning `DocumentHandler` is dropped
                if let Ok(event) = watcher_receiver.recv_timeout(timeout) {
                    if let Err(error) = async_sender.blocking_send(event) {
                        tracing::debug!(
                            "While sending file watch event watcher for document '{}': {}",
                            id,
                            error
                        );
                        break;
                    }
                }
            }
            tracing::trace!("Ending document watcher for '{}' at '{}'", id, path_string);

            // Drop the sync send so that the event handling thread also ends
            drop(async_sender);

            Ok(())
        });

        // Async task to handle events
        tokio::spawn(async move {
            let mut document_path = path_cloned;
            tracing::trace!("Starting document handler");
            while let Some(event) = async_receiver.recv().await {
                match event {
                    DebouncedEvent::Create(path) | DebouncedEvent::Write(path) => {
                        let doc = &mut *document.lock().await;
                        doc.react(&path).await;
                        if path == document_path {
                            doc.modified(path.clone()).await
                        }
                    }
                    DebouncedEvent::Remove(path) => {
                        let doc = &mut *document.lock().await;
                        doc.react(&path).await;
                        if path == document_path {
                            doc.deleted(path)
                        }
                    }
                    DebouncedEvent::Rename(from, to) => {
                        let doc = &mut *document.lock().await;
                        doc.react(&from).await;
                        doc.react(&to).await;
                        if from == document_path {
                            document_path = to.clone();
                            doc.renamed(from, to)
                        }
                    }
                    _ => {}
                }
            }
            // Because we abort this thread, this entry may never get
            // printed (only if the `async_sender` is dropped before this is aborted)
            tracing::trace!("Ending document handler");
        })
    }
}

#[cfg(test)]
mod tests {
    use test_utils::fixtures;

    use super::*;

    #[tokio::test]
    async fn new() {
        let doc = Document::new(None, None);
        assert!(doc.path.starts_with(env::temp_dir()));
        assert!(doc.temporary);
        assert!(matches!(doc.status, DocumentStatus::Synced));
        assert_eq!(doc.format.extension, "txt");
        assert_eq!(doc.content, "");
        assert_eq!(doc.subscriptions, HashMap::new());

        let doc = Document::new(None, Some("md".to_string()));
        assert!(doc.path.starts_with(env::temp_dir()));
        assert!(doc.temporary);
        assert!(matches!(doc.status, DocumentStatus::Synced));
        assert_eq!(doc.format.extension, "md");
        assert_eq!(doc.content, "");
        assert_eq!(doc.subscriptions, HashMap::new());
    }

    #[tokio::test]
    async fn open() -> Result<()> {
        for file in &["elife-small.json", "era-plotly.json"] {
            let doc = Document::open(fixtures().join("articles").join(file), None).await?;
            assert!(!doc.temporary);
            assert!(matches!(doc.status, DocumentStatus::Synced));
            assert_eq!(doc.format.extension, "json");
            assert!(!doc.content.is_empty());
            assert_eq!(doc.subscriptions, HashMap::new());
        }

        Ok(())
    }
}
